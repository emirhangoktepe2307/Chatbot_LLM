import pandas as pd
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import json
from openai import OpenAI
import os
from dotenv import load_dotenv
from email_request import send_teacher_email_inform
import re
import chromadb
from chromadb.utils import embedding_functions

# .env dosyasÄ±nÄ± yÃ¼kle
load_dotenv()

#API birden fazla kullanÄ±cÄ±da mevcut ve deadlock-fork sÃ¼reÃ§ zarflarÄ±nÄ±n uyarÄ±sÄ±nÄ± veriyordu Ã§Ä±ktÄ±yÄ± sadeleÅŸtirdim burada
os.environ["TOKENIZERS_PARALLELISM"] = "false" 

load_dotenv()
api_key=os.getenv("OPENAI_API_KEY")
model_gpt=os.getenv("OPENAI_MODEL")

client = OpenAI(api_key=api_key)

# Sohbet geÃ§miÅŸini tutacak liste
conversation_history = []

# ChromaDB istemcisini RAM Ã¼zerinde oluÅŸtur
chroma_client = chromadb.Client()
embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction()

# Koleksiyonu oluÅŸtur veya var olanÄ± al
collection = chroma_client.get_or_create_collection(
    name="ai_egitim_sorulari",
    embedding_function=embedding_function
)

# JSON dosyasÄ±ndan verileri oku
with open('Hafta-1/data.json', 'r', encoding='utf-8') as file:
    data = json.load(file)

# DataFrame'e Ã§evir
df = pd.DataFrame(data)

model = SentenceTransformer("paraphrase-multilingual-MiniLM-L12-v2")

# Embedding'leri hesapla (Sorular Ã¼zerinden)
embeddings = model.encode(df["Sorular"].tolist())

def is_relevant(question, topic_keywords=None):
    if topic_keywords is None:
        topic_keywords = [
    # Genel kavramlar
    "makine Ã¶ÄŸrenmesi", "machine learning",
    "yapay zeka", "artificial intelligence",
    "model", "veri", "data", "dataset", "veri seti", "veri Ã¶n iÅŸleme", "preprocessing", "API",
    "tahmin", "prediction", "algoritma", "algorithm", "eÄŸitim", "training",
    
    # Ã–ÄŸrenme tÃ¼rleri
    "denetimli", "denetimsiz", "supervised", "unsupervised",
    "pekiÅŸtirmeli", "reinforcement", "etiketli veri", "labeled data",
    "etiketsiz", "unlabeled", "kÃ¼meleme", "clustering",
    
    # Algoritmalar
    "regresyon", "lineer regresyon", "lojistik regresyon",
    "sÄ±nÄ±flandÄ±rma", "karar aÄŸacÄ±", "decision tree",
    "random forest", "rf", "knn", "naive bayes",
    "ann", "yapay sinir aÄŸÄ±", "neural network", "cnn", "rnn",
    "svm", "destek vektÃ¶r makineleri", "gradient boosting", "xgboost",
    "polinom regresyon", "ridge regresyon", "lasso regresyon",
    "elastic net", "ensemble", "bagging", "boosting",

    # BÃ¼yÃ¼k modeller
    "llm", "large language model", "transformer", "bert", "gpt",
    "deep learning", "derin Ã¶ÄŸrenme", "nÃ¶ron", "neuron",

    # KÃ¼tÃ¼phaneler / Framework'ler
    "tensorflow", "pytorch", "scikit-learn", "scikit", "Sklearn", "numpy", "np", "pandas", "pd", "matplotlib", "seaborn", "sns",
    "keras", "sequential", "model oluÅŸturma", "model creation",

    # Veri iÅŸleme
    "encode", "encoding", "one-hot encoding", "label encoding",
    "Ã¶lÃ§ekleme", "scaling", "min-max scaling", "z-score", "robust scaling",
    "logaritmik dÃ¶nÃ¼ÅŸÃ¼m", "feature engineering", "normalizasyon", "standardizasyon",
    "imputation", "eksik veri", "missing data", "veri temizleme", "data cleaning",

    # DeÄŸerlendirme metrikleri
    "r2", "f1 score", "rmse", "mae", "mse", "doÄŸruluk", "accuracy", "precision", "recall",
    "confusion matrix", "karmaÅŸÄ±klÄ±k matrisi", "true positive", "false positive",

    # DiÄŸer teknik terimler
    "confusion matrix", "cross-validation", "hyperparameter", "overfitting", "underfitting",
    "loss function", "activation function", "optimizer", "learning rate", "epoch", "batch size", "logloss",
    "veri bÃ¶lme", "train test split", "veri seti", "dataset", "eÄŸitim", "test",
    "gÃ¶rselleÅŸtirme", "visualization", "plot", "grafik", "chart"
    ]

    user_q = question.lower()
    return any(kw in user_q for kw in topic_keywords)

# Embedding'i DataFrame'e ekle
df["Embedding"] = embeddings.tolist()

def ask_gpt(question):
    try:
        print("\nGPT'ye soru soruluyor, lÃ¼tfen bekleyiniz...")

        # Sohbet geÃ§miÅŸini mesajlara ekle
        messages = [
            {"role": "system", "content": "Sen deneyimli bir makine Ã¶ÄŸrenmesi uzmanÄ±sÄ±n. Sorulara TÃ¼rkÃ§e olarak, teknik detaylarÄ± aÃ§Ä±klayarak ve Ã¶rnekler vererek cevap ver. CevaplarÄ±n kÄ±sa ve Ã¶z olsun."}
        ]
        
        # Son 5 mesajÄ± ekle (baÄŸlamÄ± korumak iÃ§in)
        messages.extend(conversation_history[-5:] if conversation_history else [])
        
        # Yeni soruyu ekle
        messages.append({"role": "user", "content": question})

        response = client.chat.completions.create(
            model=model_gpt,
            messages=messages,
            temperature=0.5,
            max_tokens=800,
            top_p=0.9,
            frequency_penalty=0.3,
            presence_penalty=0.3
        )

        answer = response.choices[0].message.content
        
        # Sohbet geÃ§miÅŸine ekle
        conversation_history.append({"role": "user", "content": question})
        conversation_history.append({"role": "assistant", "content": answer})
        
        # Yeni soru-cevap Ã§iftini ChromaDB'ye ekle
        collection.add(
            documents=[question],
            metadatas=[{
                'title': 'GPT CevabÄ±',
                'keywords': ', '.join(re.findall(r'\w+', question.lower()))
            }],
            ids=[f"gpt_{len(collection.get()['ids']) + 1}"]
        )
        
        return answer

    except Exception as e:
        return f"âš ï¸ GPT'ye soru sorulurken bir hata oluÅŸtu:\n{str(e)}"

def get_learning_resources(topic):
    """Konuyla ilgili Ã¶ÄŸretici web sitelerini Ã¶nerir."""
    try:
        response = client.chat.completions.create(
            model=model_gpt,
            messages=[
                {"role": "system", "content": "Sen bir eÄŸitim danÄ±ÅŸmanÄ±sÄ±n. Verilen konuyla ilgili en iyi Ã¶ÄŸretici web sitelerini, kurslarÄ± ve kaynaklarÄ± Ã¶ner. Sadece TÃ¼rkÃ§e ve Ä°ngilizce kaynaklarÄ± Ã¶ner."},
                {"role": "user", "content": f"{topic} konusuyla ilgili Ã¶ÄŸretici web siteleri ve kaynaklar Ã¶nerir misin?"}
            ],
            temperature=0.7,
            max_tokens=500
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"âš ï¸ Kaynak Ã¶nerileri alÄ±nÄ±rken bir hata oluÅŸtu:\n{str(e)}"
    
def keyword_match(question, df, min_overlap=2):
    question_tokens = re.findall(r'\w+', question.lower())

    best_match_index = -1
    max_overlap = 0

    for idx, row in df.iterrows():
        keywords = row.get("Keywords", [])
        if not keywords:
            continue
        overlap = len(set(question_tokens) & set([kw.lower() for kw in keywords]))
        if overlap > max_overlap:
            max_overlap = overlap
            best_match_index = idx

    if max_overlap >= min_overlap:
        return df.iloc[best_match_index]["Cevaplar"]
    else:
        return None

def is_topic_change(question):
    """Yeni bir konu baÅŸlÄ±ÄŸÄ± olup olmadÄ±ÄŸÄ±nÄ± kontrol eder."""
    # EÄŸer sohbet geÃ§miÅŸi boÅŸsa, yeni konu deÄŸildir
    if not conversation_history:
        return False
        
    # Son soruyu al
    last_question = conversation_history[-2]["content"] if len(conversation_history) >= 2 else ""
    
    # Son soru ve yeni soru arasÄ±nda anahtar kelime benzerliÄŸi kontrol et
    last_tokens = set(re.findall(r'\w+', last_question.lower()))
    new_tokens = set(re.findall(r'\w+', question.lower()))
    
    # Ortak kelime sayÄ±sÄ±
    common_words = len(last_tokens.intersection(new_tokens))
    
    # EÄŸer ortak kelime sayÄ±sÄ± Ã§ok azsa veya hiÃ§ yoksa, yeni konu olarak kabul et
    return common_words < 2

def find_answer(question):
    # Yeni konu kontrolÃ¼
    if is_topic_change(question):
        print("\nğŸ”„ Yeni bir konuya geÃ§ildiÄŸi tespit edildi. Sohbet geÃ§miÅŸi temizleniyor...")
        clear_conversation()
    
    # 0ï¸âƒ£ Ä°lk olarak konuyla alakalÄ± mÄ± kontrol et
    if not is_relevant(question):
        return "âš ï¸ Bu soru makine Ã¶ÄŸrenmesi veya yapay zeka konularÄ±yla ilgili gÃ¶rÃ¼nmÃ¼yor."

    # 1ï¸âƒ£ Sonra keyword eÅŸleÅŸmesine bak
    keyword_based_answer = keyword_match(question, df)
    if keyword_based_answer:
        print("âœ… Anahtar kelimelerle eÅŸleÅŸme bulundu.")
        return keyword_based_answer

    # 2ï¸âƒ£ EÅŸleÅŸme yoksa ChromaDB'de ara
    print("ğŸ” ChromaDB'de benzer sorular aranÄ±yor...")
    results = collection.query(
        query_texts=[question],
        n_results=1
    )
    
    if results['documents'] and len(results['documents'][0]) > 0:
        print("âœ… ChromaDB'de benzer soru bulundu.")
        return results['documents'][0][0]
        
    else:
        print("ğŸ¤– GPT'ye yÃ¶nlendiriliyor...")
        return ask_gpt(question)

def clear_conversation():
    """Sohbet geÃ§miÅŸini temizler."""
    global conversation_history
    conversation_history = []
    print("\nâœ… Sohbet geÃ§miÅŸi temizlendi.")

# Ana menÃ¼
def show_menu():
    print("\n=== ANA MENÃœ ===")
    print("1. Soru Sor")
    print("2. Sohbet GeÃ§miÅŸini Temizle")
    print("3. Ã‡Ä±kÄ±ÅŸ")
    return input("SeÃ§iminiz (1-3): ")

# Ana dÃ¶ngÃ¼
while True:
    choice = show_menu()
    
    if choice == '1':
        user_question = input("\nSorunuzu yazÄ±n (Ã‡Ä±kmak iÃ§in 'q' yazÄ±n): ")
        if user_question.lower() == 'q':
            continue
            
        answer = find_answer(user_question)
        print("\nCevap:", answer)
        if not answer.startswith("âš ï¸"):
            user_select = input("\nAnlamadÄ±ysan eÄŸer daha detaylÄ± bir cevap oluÅŸturmamÄ± ister misin? (y/n)")
            
            if user_select.lower() == 'y':
                new_answer = ask_gpt(user_question)
                print("\nDetaylÄ± Cevap:", new_answer)
                user_control = input("\nBu detaylÄ± aÃ§Ä±klamayÄ± anladÄ±nÄ±z mÄ±? (y/n)")
                if user_control.lower() == 'n':
                    send_teacher_email_inform(user_question)
                    print("\nHocanÄ±za Konuyla AlakalÄ± Bilgilendirme YapÄ±ldÄ±. Ä°letiÅŸime GeÃ§ene Kadar Alternatif Kaynak Ã–nermemi Ä°ster Misin.(y/n)")
                    if input().lower() == 'y':
                        resources = get_learning_resources(user_question)
                        print("\nğŸ“š Ã–nerilen Kaynaklar:")
                        print(resources)
                
    elif choice == '2':
        clear_conversation()
        
    elif choice == '3':
        print("\nProgram sonlandÄ±rÄ±lÄ±yor...")
        break
        
    else:
        print("\nGeÃ§ersiz seÃ§im! LÃ¼tfen 1-3 arasÄ±nda bir sayÄ± girin.")
        